# TraceForge Environment Configuration
# Copy this to .env and fill in your values

# ===========================================
# Required: At least one AI provider API key
# ===========================================

# OpenAI (GPT-4, GPT-3.5)
OPENAI_API_KEY=sk-your-openai-key-here

# ===========================================
# Optional: Additional AI Providers
# ===========================================

# Anthropic (Claude 3)
# ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here

# Google (Gemini)
# GEMINI_API_KEY=your-gemini-key-here

# Ollama runs locally - no key needed
# Just ensure Ollama is running: ollama serve

# ===========================================
# Optional: Custom Ports
# ===========================================

# Proxy server port (default: 8787)
# PROXY_PORT=8787

# Web server port (default: 3001)
# PORT=3001

# ===========================================
# Optional: Advanced Configuration
# ===========================================

# Environment mode (development or production)
# NODE_ENV=development

# Log level (debug, info, warn, error)
# LOG_LEVEL=info

# Enable CORS (true or false)
# ENABLE_CORS=true

# ===========================================
# Quick Start
# ===========================================
# 1. Copy this file: cp .env.example .env
# 2. Add your OPENAI_API_KEY
# 3. Run: npx pnpm dev
# 4. Open: http://localhost:5173
